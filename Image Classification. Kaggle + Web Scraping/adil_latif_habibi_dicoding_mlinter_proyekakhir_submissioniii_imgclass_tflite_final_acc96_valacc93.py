# -*- coding: utf-8 -*-
"""Adil_Latif_Habibi_Dicoding_MLInter_ProyekAkhir_SubmissionIII_ImgClass.TFLite.Final.Acc96.ValAcc93.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14dXPuUq_gwAm4UThfM5yOjAmABzi_stD

##*1. Import semua Library yang diperlukan*
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install split-folders
import splitfolders 
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Input
from scipy.special import softmax
from keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout
import matplotlib.pyplot as plt
# %matplotlib inline
import pathlib

"""##*2. Mount data dari Google Drive kemudian ekstrak* """

from google.colab import drive
drive.mount('/content/gdrive')

!unzip gdrive/My\ Drive/Data/dataset_binatang.zip

"""##*3. Split Folder menjadi Folder data training dan validasi*"""

splitfolders.ratio("dataset_binatang", output="dataset_binatang_split", seed=1337, ratio=(.8, .2), group_prefix=None)

os.listdir('/content/dataset_binatang_split')

os.listdir('/content/dataset_binatang_split/train')

os.listdir('/content/dataset_binatang_split/val')

"""##*4. Menghitung jumlah gambar yang ada pada setiap subfolder train dan val*"""

print('total gambar KUCING di folder TRAIN :', len(os.listdir('/content/dataset_binatang_split/train/cat')))
print('total gambar CHEETAH di folder TRAIN :', len(os.listdir('/content/dataset_binatang_split/train/cheetah')))
print('total gambar ORANG UTAN di folder TRAIN :', len(os.listdir('/content/dataset_binatang_split/train/orang utan')))
print('total gambar PANDA di folder TRAIN :', len(os.listdir('/content/dataset_binatang_split/train/panda')))

print('total gambar KUCING di folder VAL :', len(os.listdir('/content/dataset_binatang_split/val/cat')))
print('total gambar CHEETAH di folder VAL :', len(os.listdir('/content/dataset_binatang_split/val/cheetah')))
print('total gambar ORANG UTAN di folder VAL :', len(os.listdir('/content/dataset_binatang_split/val/orang utan')))
print('total gambar PANDA  di folder VAL :', len(os.listdir('/content/dataset_binatang_split/val/panda')))

"""##*5. Preprocessing Data*"""

train_dir = "dataset_binatang_split/train"
val_dir = "dataset_binatang_split/val"

tinggi = 64
lebar = 64
batch_size = 16
class_mode = 'categorical'

# Augmentasi Data Gambar/Photo
train_datagenerator = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=25,
    horizontal_flip=True,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    fill_mode='nearest')

# Data augmentation pada data training saja sehingga dapat menjaga konsistensi terhadap data validation yang digunakan sebagai referensi
validation_datagenerator = ImageDataGenerator(
    rescale=1.0/255)

train_generator = train_datagenerator.flow_from_directory(train_dir,
                                                    batch_size=batch_size,
                                                    class_mode=class_mode,
                                                    target_size=(tinggi, lebar),
                                                    shuffle=True)

validation_generator = validation_datagenerator.flow_from_directory(val_dir,
                                                            batch_size=batch_size,
                                                            class_mode=class_mode,
                                                            target_size=(tinggi, lebar),
                                                            shuffle=True)

"""##*6. Membuat Model*"""

# Model ini menggunakan layer Conv2d MaxPooling, Flatten, Dense, dan Dropout

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(512, (3,3), activation='relu', input_shape=(64, 64, 3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2), 
    tf.keras.layers.Dense(4, activation='softmax')  
])
model.summary()

"""##*7. Setting Optmizer*"""

int_lr = lr=0.0001
num_epochs = 150

optimizer = tf.optimizers.Adam(lr=int_lr)
model.compile(optimizer=optimizer,
              loss='categorical_crossentropy',
              metrics=['accuracy'])

"""##*8. Callback*"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') >= 0.92 and logs.get('val_accuracy') >= 0.92):
      self.model.stop_training = True
      print("\nAkurasi dan Val Akurasi sudah melebihi 92% !\nHentikan Training!")
callbacks = myCallback()

"""##*9. Latih Model*"""

history = model.fit(train_generator,
              epochs=num_epochs,
              validation_data=validation_generator,
              verbose=2,
              batch_size=32,
              callbacks=[callbacks])

"""## *10. Plot Akurasi dan Loss*"""

plt.figure(figsize=(10, 5))
plt.plot(history.history["accuracy"], label="training")
plt.plot(history.history["val_accuracy"], label="validation")
plt.title("Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

plt.figure(figsize=(10, 5))
plt.plot(history.history["loss"], label="training")
plt.plot(history.history["val_loss"], label="validation")
plt.title("Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

"""## *11. Simpan ke dalam format SavedModel*"""

export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

"""##*12. Convert SavedModel menjadi binatang.tflite*"""

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()
tflite_model_file = pathlib.Path('dataset_binatang.tflite')
tflite_model_file.write_bytes(tflite_model)

"""## SUBMISSION III PROYEK AKHIR MACHINE LEARNING INTERMEDIATE DICODING : IMG_CLASS TO TF_LITE : DONE. 


"""